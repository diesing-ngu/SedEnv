---
title: "MareanoGrids-SedEnv"
output:
  html_document:
    df_print: paged
---

# Introduction

The sedimentary environment (sedimentasjonsmiljø) is spatially predicted based on a response variable and predictor variables using random forest. The response variable is derived from detailed maps of the sedimentary environment developed under the MAREANO programme. These maps are down-sampled to the resolution of the predictor variables and their legend is simplified from six to three classes.

# Preparations


## Install packages

```{r packages, message=FALSE}
rm(list=ls())

library(terra)
library(raster)
library(sdmpredictors)
library(spatialEco)
library(Boruta)
library(caret)
library(usdm)
library(corrplot)
library(ggplot2)
library(sf)
library(CAST)
library(geosphere)
library(randomForest)
library(blockCV)
library(automap)
library(foreach)
library(doParallel)
library(measures)
library(forcats)
library(dplyr)
```


## Define projection and resolution

Projection based on https://projectionwizard.org/ using the AoI.

*Is it possible to automate the selection of the CSR based on the AoI?*

```{r projection}
crs <- "+proj=laea +lat_0=90 +lon_0=0 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs" 
res <- 4000
```


## Define Area of Interest (AoI)

The area of interest is defined by the predicted sediment classes. Rocks and boulders (50) define areas outside the AoI.

*Make sure to load the most up-to-date version of predicted sediment classes*

```{r aoi}
AoI <- rast("input/GrainSizeReg_folk8_classes_2023-06-28.tif")
AoI[AoI == 11] <- 1
AoI[AoI == 12] <- 1
AoI[AoI == 13] <- 1
AoI[AoI == 20] <- 1
AoI[AoI == 30] <- 1
AoI[AoI == 40] <- 1
AoI[AoI == 50] <- NA
AoI[AoI == 60] <- 1

AoI <- as.polygons(AoI, dissolve = TRUE)
```


# Predictor variables

A raster stack with potentially relevant predictor variables is loaded.

```{r load_predictors}
predictors <- rast("input/predictors_ngb.tif")
mud <- extend(rast("input/mud_2023-06-30.tif"), predictors)
predictors <- c(predictors, mud)
names(predictors)[38] <- "Mud"
```


## Ensure uniform projection

Check if AoI and predictors have the defined projection. Re-project if this is not the case.

```{r uniform_proj}
if (st_crs(AoI)$proj4string != crs) {
  AoI <- st_transform(AoI, crs)
}

if (crs(predictors) != crs) {
  predictors <- project(predictors, crs, res = res)
}
```


## Limit to predictors that are relevant for mapping the sedimentary environment

```{r limit_predictors}
predictors <- predictors[[-c(12,13,14,15,34,35,36,37)]]
names(predictors)
```


## Crop predictors to AoI

```{r crop_predictors}
predictors <- mask(crop(predictors, AoI), AoI)
plot(predictors)
```


## Minimum extent

Create a  spatial polygon giving the minimum extent of all predictors. This will be used to limit the response data to those points for which predictor variable data can be extracted.

```{r min_extent}
min_ext <- sum(predictors)
min_ext[min_ext > 0] <- 1
min_ext <- as.polygons(min_ext, dissolve = TRUE)
```


# Response variable

## Type of response?

Define which property is used as response data.

```{r response_type}
resp_type <- "SedEnv"
```


## Load response

```{r load_response}
resp <- read_sf(dsn = "input", layer = "SedEnv_4km_MaxCombArea_point_20230622")
names(resp)[2] <- resp_type
resp$SedEnv <- as.factor(resp$SedEnv)
summary(resp)
```


## Simplify classification

Code | Sedimentasjonsmiljø (original)           | Sedimentasjonsmiljø (forenklet)
---- | ---------------------------------------- | --------------------------------
1    | Avsetning fra suspensjon                 | Avsetning fra suspensjon (1)
2    | Avsetning fra suspensjon, lokal erosjon  | Avsetning fra suspensjon (1)
3    | Avsetning fra bunnstrømmer               | Erosjon/transport (5)
4    | Erosjon, lokal avsetning i forsenkninger | Erosjon/transport (5)
5    | Erosjon                                  | Erosjon/transport (5)
7    | Ingen/sakte avsetning                    | Ingen/sakte avsetning (7)

```{r simplify_response}
resp <- as.data.frame(resp)
for (n in 1:nrow(resp)) {
  if(resp[n,2] == 2) {resp[n,2] <- 1
  } else if(resp[n,2] == 3|resp[n,2] == 4) {resp[n,2] <- 5
  }
}
resp <- st_as_sf(resp)
summary(resp)
```


## Clip to minimum extent

```{r clip_response}
resp <- st_intersection(resp, st_as_sf(min_ext))
```


## Plot response on bathymetry

```{r plot_resp, warning=FALSE}
plot(predictors$BATH)
plot(resp, pch = 20, cex = 0.5, col = "black", add = TRUE)
```


## Create a regression matrix

A regression matrix is created by extracting values of the predictor variables at the response data locations.

```{r regression matrix}
rm_resp <- as.data.frame(extract(predictors, resp, bind = TRUE))
rm_resp <- rm_resp[-c(1,3)]
rm_resp$SedEnv <- droplevels(rm_resp$SedEnv)
summary(rm_resp)
```


# Predictor variable pre-selection

## Boruta algorithm

```{r boruta}
set.seed(42)
B <- Boruta(rm_resp[[1]] ~ .,data = rm_resp[2:ncol(rm_resp)], pValue = 0.05,
             maxRuns = 500)
B
par(mar=c(13,4,1,1), cex = 0.6)
plot(B, las=2, colCode = c("greenyellow", "yellow2", "red3", "cadetblue"), xlab = "")
```


## De-correlation analysis

To reduce redundancy in information, a de-correlation analysis is carried out. Of those predictor variables identified as important in the Boruta analysis, only those with a correlation coefficient below a set threshold are retained. However, a universally applicable threshold does not exist. Additionally, multicollinearity, i.e., collinearity between three or more variables, might exist in the data. Variance inflation factors (VIFs) are therefore additionally calculated to check for multicollinearity. As a rule of thumb, VIFs larger than 5 or 10 indicate a problematic amount of collinearity (James et al., 2017: pp. 101-102; doi: 10.1080/24754269.2021.1980261). According to Johnston et al. (2017; doi: 10.1007/s11135-017-0584-6) a VIF of 2.5 or greater is generally considered indicative of considerable collinearity.

```{r de-corr, message=FALSE, warning=FALSE}
th <- 1

repeat{
 cor_result<- vifcor(rm_resp[rownames(subset(attStats(B), decision == "Confirmed"))], th = th,  maxobservations = nrow(rm_resp))
 if (max(cor_result@results[,2]) >= 5){
   th <- th - 0.01
 } else {
   break
 }
}

max(cor_result@results[,2])
cor_result


sel_preds <- cor_result@results$Variables
seldata <- rm_resp[c(resp_type, sel_preds)]
```


##  Correlation plot

```{r correlation_plot}
corrplot.mixed(cor(rm_resp[sel_preds]), lower.col =  "black", tl.pos = "lt", number.cex = 0.6)
```


# Data exploration

## Box plots

```{r box_plots}
#Colours for the classes in numerical order
col.pal <- c(rgb(97,161,252, maxColorValue = 255), rgb(235,141,141, maxColorValue = 255), rgb(145,170,215, maxColorValue = 255))

for (i in 2:ncol(seldata)) {
  
  print(ggplot(seldata, aes(x = SedEnv, y = seldata[,i],fill = SedEnv)) +
          geom_boxplot() +
          scale_fill_manual(values = col.pal) +
          scale_y_continuous(name = names(seldata[i])) +
          theme(axis.text.x = element_blank(),
                axis.title.x = element_blank(),
                axis.ticks.x = element_blank()))
  
  }
```


## Density curves

```{r density_curves}
for (i in 2:ncol(seldata)) {
    
  print(ggplot(seldata, aes(x= seldata[,i], fill = SedEnv)) +
          geom_density(position="identity", alpha=0.6)+
          scale_fill_manual(values = col.pal) +
          scale_x_continuous(name = names(seldata[i])))
  }

```


## Environmental space

A visual check to what extent the samples cover the environmental space. This is useful as legacy data were used and no formal sampling design was applied in the analysis.

* Blue: Samples

* Grey: Environmental data (based on random subsample)

```{r}
smp <- as.data.frame(spatSample(x = predictors[[sel_preds]], size = nrow((rm_resp)), method = "random", na.rm = TRUE))

for (i in sel_preds) {
    
  print(ggplot() +
          geom_density(data = seldata, aes(x=seldata[,i]),colour="cornflowerblue",fill="cornflowerblue", alpha=0.1,linewidth=1) +
          geom_density(data = smp, aes(x=smp[,i]), colour="grey",fill="grey", alpha=0.1, linewidth=1) +
          scale_x_continuous(name = names(seldata[i])))
        
}
```


## 2D plots of environmental space

```{r 2d_env_plots}

for (i in sel_preds[2:length(sel_preds)]) {
  
  print(ggplot() +
    geom_point(data = smp, aes(x=smp[,i], y=seldata[,2]), colour="grey", alpha=1, size=2) +
    geom_point(data = seldata, aes(x=seldata[,i], y=seldata[,2]),colour="cornflowerblue", alpha=1, size=2) +
    scale_x_continuous(name = names(seldata[i])) +
    ylab(sel_preds[1]) +
    theme_bw())
}
```


## Distances in geographic space

```{r geogr_space_dist}
dist_geogr <- plot_geodist(resp, predictors,
                     type = "geo",
                     unit="km",
                     showPlot = FALSE)


dist_geogr$plot + scale_x_log10() + scale_y_sqrt()
```



# Random Forest model

A Random Forest (Breiman, 2001) model is built, based on the response variable (SedEnv) and selected predictor variables.


## Quick model without spatial CV

```{r quick_rf}
set.seed(42)
rf <- randomForest(SedEnv ~ ., data = seldata, replace = FALSE)
rf
```


The response data are likely spatially structured. Spatial autocorrelation might lead to over-optimistic estimates of performance metrics. To account for spatial autocorrelation, a k-fold cross-validation approach is taken.

First, the spatial autocorrelation range of the individual classes is determined. To achieve this, the classes are transformed to presences-absence data.The median or maximum range of the fitted variogram models is taken as the spatial autocorrelation range, which will be used to determine block size.


## Creating presence-absence data

```{r pa_data}
resp$C1 <- 0
resp$C5 <- 0
resp$C7 <- 0

resp <- as.data.frame(resp)
for (n in 1:nrow(resp)) {
  if (resp[n,2] == "1") {resp[n,5] <- 1}
  if (resp[n,2] == "5") {resp[n,6] <- 1}
  if (resp[n,2] == "7") {resp[n,7] <- 1}
}
resp <- st_as_sf(resp)
summary(resp)
```


## Spatial autocorrelation range

The spatial dependence structure in the raw data is determined. Specifically, the distance (range) up to which observations are spatially autocorrelated is estimated with a variogram.

```{r spatial_autocorrelation_range}
#Class 1 (Avsetning fra suspensjon)
v1 <- autofitVariogram(C1 ~ 1, resp)
plot(v1)

#Class 5 (Erosjon/transport)
v5 <- autofitVariogram(C5 ~ 1, resp)
plot(v5)

#Class 7 (Ingen/sakte avsetning)
v7 <- autofitVariogram(C7 ~ 1, resp)
plot(v7)

sar <- median(c(v1$var_model$range[2], v5$var_model$range[2], v7$var_model$range[2]))

#OR

#sar <- max(c(v1$var_model$range[2], v5$var_model$range[2], v7$var_model$range[2]))
```


## Creating spatial blocks

Spatial blocks and folds are created. The folds will be used in a spatial k-fold cross validation. The size of the blocks is determined by the spatial autocorrelation range.

Roberts et. al. (2017) suggest that blocks should be substantially bigger than the range of spatial autocorrelation (in model residual) to obtain realistic error estimates, while a buffer with the size of the spatial autocorrelation range would result in a good estimation of error.

*Should we increase the block size? This could be gauged by looking at the geographic distances plot below. The block size might be right, when sample-to-prediction and CV distances look similar.*

```{r spatial_blocks}
k <- 10 # Number of folds
m <- 2 # Multiplier applied to block size

spBlocks <- cv_spatial(resp,
                       k = k,
                       #hexagon = FALSE,
                       size = sar * m,
                       seed = 42,
                       progress = FALSE)
```


## Reshaping index

The output from the blocking step needs to be reshaped.

```{r reshape_index}
# Spatial blocks
index_train <- list()
index_val <- list()
for (n in 1:spBlocks$k) {
  ft <- spBlocks[["folds_list"]][[n]][[-2]]
  fv <- spBlocks[["folds_list"]][[n]][[2]]
  index_train[[length(index_train)+1]] <- ft
  index_val[[length(index_val)+1]] <- fv
}
```


## Distances in geographic space including CV distances

```{r geogr_space_dist2}
dist_geogr2 <- plot_geodist(resp, predictors,
                     cvfolds= index_val,
                     type = "geo",
                     unit="km",
                     showPlot = FALSE)

dist_geogr2$plot + xlim(0,200) + ylim(0,0.05)
dist_geogr2$plot + scale_x_log10() + ylim(0,2)
```


## Model tuning

A Random Forest model is tuned. Predictor variables are finally selected in a forward feature selection approach and various values of the mtry parameter are tested in a spatial k-fold cross validation.

This step is time-consuming and memory-heavy. Therefore, only a subset of possible mtry values is tested. These are multiples of the default mtry values or the default values. 

The maximum number of iterations can be calculated upfront, based on the number of pre-selected predictors:

```{r max_iter}
factorial(length(sel_preds))/(factorial(2)*factorial(length(sel_preds)-2)) + sum(c((length(sel_preds)-2):1))
```


### Forward feature selection

The best combination of predictor variables (features) is found in a forward feature selection process.

```{r model_tuning}
nCores <- detectCores()
cl <- makePSOCKcluster(nCores - 1)
registerDoParallel(cl)

set.seed(42)

model <- ffs(seldata[sel_preds],
               seldata$SedEnv,
               method="rf",
               replace = FALSE,
               importance=TRUE,
               trControl = trainControl(method="CV", 
                                        number = k,
                                        savePredictions = "final",
                                        index = index_train, 
                                        allowParallel = TRUE),
               verbose = TRUE)

stopCluster(cl)

model

sel_preds <- model$selectedvars
```


### FFS plot

Plot of Accuracy over the model runs.

```{r ffs_plot}
plot_ffs(model)
```


## Validation statistics

The validation results of the optimal RF model.

Note that these are the statistics based on the predicted values of the selected model. These differ from the values from the tuning (above), which are the means of the k predictions based on the folds.

```{r validation_stats}
t <- data.frame(model$pred$pred, model$pred$obs)
summary(t)

acc <- caret::confusionMatrix(data = t$model.pred.pred, reference = t$model.pred.obs)
acc

ber <- BER(t$model.pred.obs, t$model.pred.pred)
print(paste("BER = ", round(ber, 2)))

write.table(acc$table, file = "output/ContingencyTable.txt")
```


## Errors of commission and omission

```{r class_errors}
EoC <- round(100 - (diag(acc$table) / rowSums(acc$table) * 100), 2)
EoO <- round(100 - (diag(acc$table) / colSums(acc$table) * 100), 2)

class_error <- data.frame(EoC, EoO)
names(class_error) <- c("Error of commission", "Error of omission")
class_error
```


## Variable importance

RF also provides a relative estimate of predictor variable importance. This is measured as the mean decrease in accuracy associated with each variable when it is assigned random but realistic values and the rest of the variables are left unchanged.
type = 1: mean decrease in accuracy, scale = FALSE: unscaled

```{r variable_importance}
plot(varImp(model, scale = FALSE), col = "black")
```


## Predict Random Forest

The probabilities of individual classes are predicted. Then, maximum probabilities are derived for every pixel in the map. This gives the probability associated with the class in the categorical prediction, which is finally predicted.

### Predicted probabilities

```{r probabilities}
sel_pred_stack <- stack(predictors[[sel_preds]])

rfprob <- predict(sel_pred_stack, model$finalModel, type="prob", index = model$levels)
names(rfprob) <- model$levels
rfprob
plot(rfprob)
```


### Calculate maximum probability

```{r max_probability}
max_prob <- max(rfprob)
max_prob
plot(max_prob)
```


### Predicted classes

```{r classes}
rfres <- predict(sel_pred_stack, model$finalModel)
rfres
plot(rfres)
```


## Area of applicability

The area of applicability of the model is determined.

```{r aoa_resp}
resp_trainDI <- trainDI(model = model,
                        variables = sel_preds)
print(resp_trainDI)

resp_aoa <- aoa(newdata = predictors, 
                model = model,
                trainDI = resp_trainDI,
                variables = sel_preds
                )

plot(resp_aoa)
```



### Plot AOA

```{r plot_aoa}
plot(resp_aoa$DI, main = "Dissimilarity index")
plot(resp_aoa$AOA, main = "Area of applicability")

fr <- freq(resp_aoa$AOA)
print(paste0("AOA = ", round(100*fr$count[2]/ sum(fr$count),2), "% of pixels"))
```


## Convert AOA from raster to polygon

```{r aoa_poly}
aoa_poly <- as.polygons(resp_aoa$AOA, dissolve = TRUE)
plot(aoa_poly)

write_sf(st_as_sf(aoa_poly), dsn = "output", layer = paste0(resp_type, "3_AOA_", Sys.Date()), driver = "ESRI Shapefile")
```


## Export Rasters

The results are exported as GeoTiffs for further analysis.

```{r export_rasters}
writeRaster(rfres, paste0("output/", resp_type, "3_classes", Sys.Date(), ".tif"))
writeRaster(rast(rfprob), paste0("output/", resp_type, "3_probabilities_", Sys.Date(), ".tif"), names = model$levels)
writeRaster(max_prob, paste0("output/", resp_type, "3_max_probabilities", Sys.Date(), ".tif"))
writeRaster(resp_aoa$DI, paste0("output/", resp_type, "3_DI", Sys.Date(),".tif"))
writeRaster(resp_aoa$AOA, paste0("output/", resp_type, "3_AOA", Sys.Date(), ".tif"))
```


## Output a log file

```{r log}
sink(file = paste0("output/ModelLog_", Sys.Date(), ".txt"))
print("Selected Predictors")
sel_preds
model
print("Final Model")
acc
print("Error of commission")
EoC
print("Error of omission")
EoO
paste0("AOA = ", round(100*fr$count[2]/ sum(fr$count),2), "% of pixels")
sink()
```


# Finishing off

## Save RF model

```{r save_model}
saveRDS(model, paste0(resp_type, "3_rfmodel.rds"))
```


## Save session info

```{r save_session_info}
sessionInfo <- sessionInfo()
save(sessionInfo, file = paste0(resp_type, "3_sessionInfo.Rdata"))
rm("sessionInfo")
```


## Save global environment

```{r save_global_env}
save.image(file = paste0(resp_type, "3_globEnv.RData"))
```
